{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxpldO9EnwN1"
   },
   "source": [
    "In this recitation we will cover diffusion models.\n",
    "This recitation has been adapted from [this](https://github.com/ThiagoLira/ToyDiffusionhttps://github.com/ThiagoLira/ToyDiffusion) repository.\n",
    "Some of the key diffusion model functions have been reimplemented using ChatGPT and the goal is to debug.\n",
    "The prompts used to generate the diffusion model code have been given in addition to the ChatGPT generated code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XGrHnaCp1hBA",
    "outputId": "8801bc7c-e800-4b18-dda0-48894bdda139"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from utils import pack_data, unpack_1d_data, scatter_pixels\n",
    "from tqdm import tqdm\n",
    "!pip install celluloid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pmRs7eJs1hBB"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' # It is highly recommended to use a GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCcAXx0q39rI"
   },
   "source": [
    "## Diffusion Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JnLOqnTt38yX"
   },
   "outputs": [],
   "source": [
    "def denoise_with_mu(denoise_model, x_t, t, list_alpha, list_alpha_bar, DATA_SIZE, device):\n",
    "    \"\"\"\n",
    "    Denoising function considering the denoising models tries to model the posterior mean\n",
    "    \"\"\"\n",
    "    alpha_t = list_alpha[t]\n",
    "    beta_t = 1 - alpha_t\n",
    "    alpha_bar_t = list_alpha_bar[t]\n",
    "    \n",
    "    mu_theta = denoise_model(x_t,t)\n",
    "    \n",
    "    x_t_before = torch.distributions.MultivariateNormal(loc=mu_theta,covariance_matrix=torch.diag(beta_t.repeat(DATA_SIZE))).sample().to(device)\n",
    "        \n",
    "    return x_t_before\n",
    "\n",
    "    \n",
    "def position_encoding_init(n_position, d_pos_vec):\n",
    "    ''' \n",
    "    Init the sinusoid position encoding table \n",
    "    n_position in num_timesteps and d_pos_vec is the embedding dimension\n",
    "    '''\n",
    "    # keep dim 0 for padding token position encoding zero vector\n",
    "    position_enc = np.array([\n",
    "        [pos / np.power(10000, 2*i/d_pos_vec) for i in range(d_pos_vec)]\n",
    "        if pos != 0 else np.zeros(d_pos_vec) for pos in range(n_position)])\n",
    "\n",
    "    position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2]) # dim 2i\n",
    "    position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2]) # dim 2i+1\n",
    "    return torch.from_numpy(position_enc).to(torch.float32)\n",
    "\n",
    "\n",
    "class Denoising(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, x_dim, num_diffusion_timesteps):\n",
    "        super(Denoising, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(x_dim, x_dim)\n",
    "        self.emb = position_encoding_init(num_diffusion_timesteps,x_dim)\n",
    "        self.linear2 = torch.nn.Linear(x_dim, x_dim)\n",
    "        self.linear3 = torch.nn.Linear(x_dim, x_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x_input, t):\n",
    "        emb_t = self.emb[t]\n",
    "        x = self.linear1(x_input+emb_t)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjhtXxmT6ja7"
   },
   "source": [
    "## Using ChatGPT to Write Our Code\n",
    "#### Process to implement:\n",
    "Forward noising at an arbitrary timestep\n",
    "\n",
    "#### Equation to implement:\n",
    "$$q\\left(x_t|x_0\\right) = \\mathcal{N}\\left(x_t;\\sqrt{\\bar{\\alpha}_t}x_0, \\left(1-\\bar{\\alpha}_t\\right)\\mathbb{I}\\right)$$\n",
    "\n",
    "####ChatGPT Prompt: \n",
    "Write me a diffusion model function that adds noise to a sample given a time, sample, and noise schedule in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FA5Xkzc66ftv"
   },
   "outputs": [],
   "source": [
    "def add_diffusion_noise(sample, t, noise_schedule):\n",
    "    \"\"\"\n",
    "    Adds diffusion noise to the given sample at the specified time using the given noise schedule.\n",
    "\n",
    "    Args:\n",
    "        sample (torch.Tensor): The sample to add noise to.\n",
    "        t (float): The time at which to add the noise.\n",
    "        noise_schedule (torch.Tensor): The noise schedule to use. Should be a 1D tensor with the same length\n",
    "            as the dimension of the sample.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The sample with added diffusion noise.\n",
    "    \"\"\"\n",
    "    # Compute the standard deviation of the noise at this time.\n",
    "    std = (noise_schedule[t] - noise_schedule[t-1]).sqrt()\n",
    "\n",
    "    # Generate the noise tensor with the same shape as the sample.\n",
    "    noise = torch.randn_like(sample) * std\n",
    "\n",
    "    # Add the noise to the sample and return the result.\n",
    "    return sample + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Os5cJIGQvLC"
   },
   "source": [
    "#### Process to implement:\n",
    "Denoising using our trainable model\n",
    "\n",
    "#### Equations to implement:\n",
    "$$\n",
    "\\begin{align}\n",
    "    %\\mu_{\\theta} &= \\sqrt{\\bar{\\alpha}_t}\\beta_t + \\sqrt{\\alpha_t}\\left(1 - \\bar{\\alpha}_{t}\\right)x_{t}\\\\\n",
    "    \\mu_{\\theta} &= \\frac{1}{\\sqrt{\\alpha_t}}\\left( x_t - \\frac{\\beta_t}{\\sqrt{1 - \\bar{\\alpha}_t}}\\epsilon_{\\theta}\\left(x_t, t\\right)\\right)\\\\\n",
    "    \\Sigma_{\\theta} &= \\sqrt{1 - \\bar{\\alpha}_t}\\mathbb{I}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "####Prompt: \n",
    "Write me a diffusion model function that calculates the mean and variance of the posterior given noise schedule, starting sample, noisy sample, and time in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8w4Ydw7ROl2"
   },
   "outputs": [],
   "source": [
    "def compute_diffusion_posterior(noise_schedule, start_sample, noisy_sample, t):\n",
    "    \"\"\"\n",
    "    Computes the mean and variance of the posterior distribution for the given diffusion process parameters\n",
    "    and observed data.\n",
    "\n",
    "    Args:\n",
    "        noise_schedule (torch.Tensor): A 1D tensor containing the noise schedule for the diffusion process.\n",
    "        start_sample (float): The starting sample value for the diffusion process.\n",
    "        noisy_sample (float): The observed sample value at the specified time.\n",
    "        t (int): The time at which the observation was made.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: A tuple containing the mean and variance of the posterior distribution.\n",
    "    \"\"\"\n",
    "    # Compute the parameters of the prior distribution.\n",
    "    alpha = start_sample\n",
    "    beta = noise_schedule[0] ** 2 / 2\n",
    "\n",
    "    # Compute the parameters of the likelihood function.\n",
    "    y = noisy_sample\n",
    "    sigma_sq = (noise_schedule[t] ** 2 - noise_schedule[t-1] ** 2) / 2\n",
    "\n",
    "    # Compute the parameters of the posterior distribution.\n",
    "    mean = (beta * y + sigma_sq * alpha) / (beta + sigma_sq)\n",
    "    var = sigma_sq * beta / (beta + sigma_sq)\n",
    "\n",
    "    return mean, var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vXxB6ZQ1hBB"
   },
   "source": [
    "## ATTENTION ##\n",
    "###### If you do not have it, download this image https://www.infomoney.com.br/wp-content/uploads/2019/06/homer-simpson.jpg?resize=900%2C515&quality=50&strip=all and save it in this folder as 'homer.png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "To0r1FKr1hBC"
   },
   "outputs": [],
   "source": [
    "x,y = scatter_pixels('homer.png')\n",
    "x = [x/25 -3 for x in x]\n",
    "y = [y/25 -2 for y in y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQ_0B_6h1hBD"
   },
   "source": [
    "## Scatter plot of data we will try to train the model to generate from random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "IrEPDJeC1hBD",
    "outputId": "0d0e8cf0-f042-4c55-a275-5d7d08958257"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.scatterplot(x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uM8gk8sc1hBD"
   },
   "outputs": [],
   "source": [
    "## Store the ax to plot the result later\n",
    "y_ax = ax.get_ylim()\n",
    "x_ax = ax.get_xlim()\n",
    "axes = (x_ax,y_ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "03wWurYN1hBE"
   },
   "outputs": [],
   "source": [
    "# send data to device\n",
    "one_d_data = pack_data(x,y)\n",
    "x_init = torch.tensor(one_d_data).to(torch.float32).to(device)\n",
    "\n",
    "DATA_SIZE = len(x_init)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIwP8ruh1hBE"
   },
   "source": [
    "# Diffusion Parameters\n",
    "\n",
    "These parameters control the noise schedule.\n",
    "They are critical in obtaining a good diffusion model.\n",
    "Feel free to modify and see how the training process changes.\n",
    "The given parameters should work well for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNbvHW831hBE"
   },
   "outputs": [],
   "source": [
    "beta_start = .0004\n",
    "beta_end = .02\n",
    "num_diffusion_timesteps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_J8PlH3X1hBE"
   },
   "outputs": [],
   "source": [
    "from operator import mul\n",
    "from functools import reduce \n",
    "\n",
    "betas = np.linspace(beta_start ** 0.5, beta_end ** 0.5, num_diffusion_timesteps) ** 2\n",
    "alphas = 1 - betas\n",
    "\n",
    "# send parameters to device\n",
    "betas = torch.tensor(betas).to(torch.float32).to(device)\n",
    "alphas = torch.tensor(alphas).to(torch.float32).to(device)\n",
    "\n",
    "# alpha_bar_t is the product of all alpha_ts from 0 to t\n",
    "list_bar_alphas = [alphas[0]]\n",
    "for t in range(1,num_diffusion_timesteps):\n",
    "    list_bar_alphas.append(reduce(mul,alphas[:t]))\n",
    "    \n",
    "list_bar_alphas = torch.cumprod(alphas, axis=0).to(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fldwUeBW1hBF"
   },
   "source": [
    "## Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L58H21g11hBF"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "training_steps_per_epoch = 40\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "denoising_model = Denoising(DATA_SIZE, num_diffusion_timesteps).to(device)\n",
    "\n",
    "# hack to put embedding layer on 'device' as well\n",
    "denoising_model.emb = denoising_model.emb.to(device)\n",
    "optimizer = optim.AdamW(denoising_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ObUhF-UZ1hBF",
    "outputId": "50de1ac3-84ac-4195-da0e-fbaabbb7bbc3"
   },
   "outputs": [],
   "source": [
    "pbar = tqdm(range(10))\n",
    "for epoch in pbar:  # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    # sample a bunch of timesteps\n",
    "    Ts = np.random.randint(1,num_diffusion_timesteps, size=training_steps_per_epoch)\n",
    "    for _, t in enumerate(Ts):\n",
    "        # produce corrupted sample\n",
    "        q_t = add_diffusion_noise(x_init, t, list_bar_alphas)\n",
    "                \n",
    "        # calculate the mean and variance of the posterior forward distribution q(x_t-1 | x_t,x_0)\n",
    "        #mu_t, cov_t = compute_diffusion_posterior(list_bar_alphas, x_init, q_t, t)\n",
    "        mu_t, cov_t = compute_diffusion_posterior(alphas, list_bar_alphas, x_init, q_t, t)\n",
    "        \n",
    "        # get just first element from diagonal of covariance since they are all equal\n",
    "        sigma_t = cov_t[0][0]\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "  \n",
    "        mu_theta = denoising_model(q_t , t)\n",
    "        loss = criterion(mu_t, mu_theta)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.detach()\n",
    "    pbar.set_description('Epoch: {} Loss: {}'.format(epoch, running_loss/training_steps_per_epoch))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2MWqXWc1hBF"
   },
   "source": [
    "### Reserve-Diffuse one Sample of Noise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0XLFU-ia1hBF",
    "outputId": "2185d7be-ef53-4b79-a0c9-c75c8c8a9db2"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "data = torch.distributions.MultivariateNormal(loc=torch.zeros(DATA_SIZE),covariance_matrix=torch.eye(DATA_SIZE)).sample().to(device)\n",
    "\n",
    "for t in tqdm(range(0,num_diffusion_timesteps)):\n",
    "    data = denoise_with_mu(denoising_model,data,num_diffusion_timesteps-t-1, alphas, list_bar_alphas, DATA_SIZE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "T__QT8gX1hBG",
    "outputId": "785a2af4-4568-4e1b-9370-83974ede577d"
   },
   "outputs": [],
   "source": [
    "#data = data.detach().cpu().numpy()\n",
    "x_new, y_new = unpack_1d_data(data.cpu())\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x=x_new, y=y_new, s=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0cdohUy1hBG"
   },
   "source": [
    "### Create an AWESOME HD 24fps GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "gc1OqLpI1hBG",
    "outputId": "ceca31a2-be3b-4b6d-a738-99ab3732cb29"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from celluloid import Camera\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure()\n",
    "camera = Camera(fig)\n",
    "\n",
    "# animation draws one data point at a time\n",
    "data = torch.distributions.MultivariateNormal(loc=torch.zeros(DATA_SIZE),covariance_matrix=torch.eye(DATA_SIZE)).sample().to(device)\n",
    "data_plot = data.detach().cpu().numpy()\n",
    "x_new, y_new = unpack_1d_data(data_plot)\n",
    "graph = sns.scatterplot(x=x_new, y=y_new, color='goldenrod')#,palette=['green'])\n",
    "#graph = sns.scatterplot(y_new, color='green')#,palette=['green'])\n",
    "graph.set_xlim(axes[0])\n",
    "graph.set_ylim(axes[1])\n",
    "camera.snap()\n",
    "data_plot = data.detach().cpu().numpy()\n",
    "\n",
    "#data = torch.Tensor(data)\n",
    "for d in tqdm(range(1, num_diffusion_timesteps)):\n",
    "    data = denoise_with_mu(denoising_model,data,num_diffusion_timesteps-d, alphas, list_bar_alphas, DATA_SIZE, device)\n",
    "    data_plot = data.detach().cpu().numpy()\n",
    "    x_new, y_new = unpack_1d_data(data_plot)\n",
    "    graph = sns.scatterplot(x=x_new, y=y_new, color='goldenrod')#,palette=['green'])\n",
    "    #graph = sns.scatterplot(y_new, color='green')#,palette=['green'])\n",
    "    graph.set_xlim(axes[0])\n",
    "    graph.set_ylim(axes[1])\n",
    "    camera.snap()\n",
    "    data_plot = data.detach().cpu().numpy()\n",
    "\n",
    "anim = camera.animate(blit=False)\n",
    "anim.save('output.gif',fps=6, dpi=120)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "id": "wGx6IqTP1hBG",
    "outputId": "12811970-afcd-47cb-b3e6-ab70aeb2b0e5"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(open('output.gif','rb').read())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
